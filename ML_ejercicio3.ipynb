{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de clasificación de jets usando una red neuronal convolucional clásica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "print('python: '+platform.python_version())\n",
    "import numpy as np\n",
    "print('numpy: '+np.__version__)\n",
    "import matplotlib\n",
    "print('matplotlib: '+matplotlib.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "print('pandas: '+ pd.__version__)\n",
    "import keras\n",
    "print('keras: '+keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando la red neuronal convolucional (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANDO FUNCIONES\n",
    "\n",
    "from keras.models import Sequential # pip install -U keras   or   pip3 install -U keras\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "import itertools # \n",
    "from sklearn.metrics import confusion_matrix # pip install -U scikit-learn   or   pip3 install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando los datasets generados con el ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datrain=np.load('Datatrain.npy')\n",
    "Datest=np.load('Datatest.npy')\n",
    "labeltr=np.load('labeltr.npy')\n",
    "labelte=np.load('labelte.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos las dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Datrain.shape)\n",
    "print(Datest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construyendo la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTRUIR UN MODELO SECUENCIAL CON LAS SIGUIENTES CAPAS:\n",
    "# 1. CONVOLUCIÓN DE 8 CANALES, 4X4, que acepte datos de la forma (40, 40, 1)\n",
    "# 2. CONVOLUCIÓN DE 8 CANALES, 4X4, con función de activación ReLU\n",
    "# 3. MAXPOOLING2D, pool_size=(2,2)\n",
    "# 3. CONVOLUCIÓN DE 8 CANALES 4X4 con función de activación ReLU\n",
    "# 4. FLATTEN\n",
    "# 5. DENSE de 64 unidades, con función de activación ReLU\n",
    "# 6. DENSE de 64 unidades, con función de activación ReLU\n",
    "# 7. DENSE de 64 unidades, con función de activación ReLU\n",
    "# 8. DENSE de 1 unidade, con función de activación sigmoide\n",
    "\n",
    "\n",
    "#model = \n",
    "\n",
    "\n",
    "\n",
    "#model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenando la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILIZAR LA FUNCIÓN FIT con el input \"Datrain\", etiquetas \"labeltr\", batch_size=20, epochs=6, shuffle=True\n",
    "\n",
    "# history = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obteniendo una predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAR LA FUNCIÓN predict con input \"Datest\"\n",
    "# predictionL=\n",
    "\n",
    "# Redondear a enteros\n",
    "predictionL = np.around(predictionL) \n",
    "predictionL=np.asarray(predictionL,dtype=int)\n",
    "print(predictionL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficando resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the list data\n",
    "predic1 = pd.DataFrame(predictionL, columns=['Values'])\n",
    "# Plot the histogram using Pandas\n",
    "clases = pd.value_counts(predic1['Values'], sort = True)\n",
    "clases.plot(kind = 'bar', rot=0)\n",
    "plt.xticks(range(3))\n",
    "plt.title(\"Signal (1) and background (0) jet frequencies in the training set\")\n",
    "plt.xlabel(\"Output\")\n",
    "plt.ylabel(\"Number of jets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAR LA FUNCIÓN EVALUATE PARA ENCONTRAR EL COSTO Y LA EXACTITUD DEL MODELO ENTRENADO\n",
    "# Usar batch_size=32\n",
    "# test_loss, test_acc = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficando el costo por época"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El atributo 'loss' es el costo\n",
    "loss = history.history['loss']\n",
    "\n",
    "# Hacemos una lista con las épocas\n",
    "epochs = range(len(loss))\n",
    "\n",
    "# Graficar épocas vs costo\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficando exactitud por época"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El atributo 'accuracy' es la exactitud\n",
    "# modelacc = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión\n",
    "\n",
    "Investigar la función de Sklearn llamada \"confusion_matrix\". ¿Qué hace? ¿Cómo funciona? ¿Cómo implementarla para nuestro modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAR LA FUNCIÓN confusion_matrix PARA CONSTRUIR LA MATRIZ A PARTIR DE LA PREDICCIÓN\n",
    "#cm= \n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "cm_labels=['Background', 'Signal']    \n",
    "plot_confusion_matrix(cm=cm,classes=cm_labels,title='Confusion matrix CNN')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
